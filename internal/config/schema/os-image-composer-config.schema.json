{
	"$schema": "https://json-schema.org/draft/2020-12/schema",
	"$id": "https://github.com/open-edge-platform/os-image-composer/schemas/os-image-composer-config.schema.json",
	"title": "OS Image Composer Config",
	"description": "Defines the global configuration file for the OS Image Composer",
	"type": "object",
	"properties": {
		"workers": {
			"type": "integer",
			"description": "Number of concurrent workers for tasks",
			"default": 8,
			"minimum": 1,
			"maximum": 64
		},
		"config_dir": {
			"type": "string",
			"description": "Configuration file directory for the OS Image Composer",
			"default": ".config",
			"pattern": "^[a-zA-Z0-9_./-]+$",
			"minLength": 0,
			"maxLength": 255
		},
		"cache_dir": {
			"type": "string",
			"description": "Default root package cache directory",
			"default": ".cache",
			"pattern": "^[a-zA-Z0-9_./-]+$",
			"minLength": 0,
			"maxLength": 255
		},
		"work_dir": {
			"type": "string",
			"description": "Default root workspace directory",
			"default": ".workspace",
			"pattern": "^[a-zA-Z0-9_./-]+$",
			"minLength": 0,
			"maxLength": 255
		},
		"temp_dir": {
			"type": "string",
			"description": "Default temporary directory for short lived files",
			"default": ".temp",
			"pattern": "^[a-zA-Z0-9_./-]+$",
			"minLength": 0,
			"maxLength": 255
		},
		"logging": {
			"type": "object",
			"description": "Logging configuration",
			"properties": {
				"level": {
					"type": "string",
					"description": "Logging level",
					"enum": [
						"debug",
						"info",
						"warn",
						"error"
					],
					"default": "info"
				}
			},
			"required": [
				"level"
			],
			"additionalProperties": false
		},
		"ai": {
			"type": "object",
			"description": "AI/LLM configuration for template generation",
			"properties": {
				"enabled": {
					"type": "boolean",
					"description": "Enable AI-powered template generation",
					"default": false
				},
				"provider": {
					"type": "string",
					"description": "AI provider to use",
					"enum": [
						"ollama",
						"openai"
					],
					"default": "ollama"
				},
				"ollama": {
					"type": "object",
					"description": "Ollama-specific configuration",
					"properties": {
						"base_url": {
							"type": "string",
							"description": "Ollama API base URL",
							"default": "http://localhost:11434",
							"format": "uri"
						},
						"model": {
							"type": "string",
							"description": "Ollama model name",
							"default": "llama3.1:8b"
						},
						"temperature": {
							"type": "number",
							"description": "Sampling temperature (0.0-2.0)",
							"minimum": 0.0,
							"maximum": 2.0,
							"default": 0.7
						},
						"max_tokens": {
							"type": "integer",
							"description": "Maximum tokens in response",
							"minimum": 100,
							"maximum": 10000,
							"default": 2000
						},
						"timeout": {
							"type": "integer",
							"description": "Request timeout in seconds",
							"minimum": 10,
							"maximum": 600,
							"default": 120
						}
					},
					"additionalProperties": false
				},
				"openai": {
					"type": "object",
					"description": "OpenAI-specific configuration",
					"properties": {
						"api_key": {
							"type": "string",
							"description": "OpenAI API key"
						},
						"model": {
							"type": "string",
							"description": "OpenAI model name",
							"default": "gpt-4-turbo"
						},
						"temperature": {
							"type": "number",
							"description": "Sampling temperature (0.0-2.0)",
							"minimum": 0.0,
							"maximum": 2.0,
							"default": 0.7
						},
						"max_tokens": {
							"type": "integer",
							"description": "Maximum tokens in response",
							"minimum": 100,
							"maximum": 10000,
							"default": 2000
						},
						"timeout": {
							"type": "integer",
							"description": "Request timeout in seconds",
							"minimum": 10,
							"maximum": 600,
							"default": 120
						}
					},
					"additionalProperties": false
				}
			},
			"additionalProperties": false
		}
	},
	"additionalProperties": false
}
